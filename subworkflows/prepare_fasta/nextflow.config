// Main settings - normally already provided through `nextflow.config`
params {
    // Limit resources so that this can run on GitHub Actions
    max_cpus   = 2
    max_memory = '6.GB'
    max_time   = '6.h'

    // Set default values
    fasta    = null
    outdir   = './results'
    tracedir = "${params.outdir}/pipeline_info"

    // No Conda, only Singularity
    enable_conda = false
}

// Singularity settings - normally already provided through `conf/sanger.config`
singularity.enabled    = true
singularity.autoMounts = true
singularity.runOptions = '--bind /lustre --bind /nfs'

// Resource settings - add to `conf/base.config`
process {

    // Very little memory for most of the subworkflow
    withName: "PREPARE_FASTA:(CUSTOM_GETCHROMSIZES|TABIX_BGZIP)" {
        cpus   = 1
        memory = { check_max( 50.MB * task.attempt, 'memory' ) }
        time   = { check_max( 30.min * task.attempt, 'time' ) }
    }

    // samtools dict loads entire sequences in memory
    withName: 'PREPARE_FASTA:SAMTOOLS_DICT' {
        // 50 MB per 50 Mbp
        memory = { check_max( 50.MB + 50.MB * task.attempt * Math.ceil(meta.max_length / 50000000), 'memory' ) }
    }
}

// Publishing settings - add to `conf/modules.config`
process {

    // So that the .dict includes paths from Nextflow's work/ directory
    withName: 'PREPARE_FASTA:SAMTOOLS_DICT'{
        ext.args = { "--uri ${task.publishDir.path[0]}/${fasta.name}.gz" }
    }

    // In this demo workflow, we want to publish everything
    withName: "PREPARE_FASTA:.*" {
        publishDir = [
            path: params.outdir,
            mode: 'copy',
            saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
        ]
    }
}

// Dummy check_max function to make the above work
// DO NOT COPY. Your nf-core pipeline already has the correct implementation
def check_max(obj, type) {
    return obj
}
