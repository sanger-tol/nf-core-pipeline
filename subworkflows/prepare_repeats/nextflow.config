// Main settings - normally already provided through `nextflow.config`
params {
    // Limit resources so that this can run on GitHub Actions
    max_cpus   = 2
    max_memory = '6.GB'
    max_time   = '6.h'

    // Set default values
    fasta    = null
    outdir   = './results'
    tracedir = "${params.outdir}/pipeline_info"

    // No Conda, only Singularity
    enable_conda = false
}

// Singularity settings - normally already provided through `conf/sanger.config`
singularity.enabled    = true
singularity.autoMounts = true
singularity.runOptions = '--bind /lustre --bind /nfs'

// Resource settings - add to `conf/base.config`
process {

    // Very little memory for most of the subworkflow
    withName: "PREPARE_REPEATS:(REPEATS_BED|TABIX_BGZIP|TABIX_TABIX_CSI|TABIX_TABIX_TBI)" {
        cpus   = 1
        memory = { check_max( 50.MB * task.attempt, 'memory' ) }
        time   = { check_max( 30.min * task.attempt, 'time' ) }
    }
}

// Publishing settings - add to `conf/modules.config`
process {

    // Right settings for `tabix`
    withName: 'PREPARE_REPEATS:TABIX_TABIX_CSI' {
        ext.args = "--preset bed --csi"
    }
    withName: 'PREPARE_REPEATS:TABIX_TABIX_TBI' {
        ext.args = "--preset bed"
    }

    // In this demo workflow, we want to publish everything
    withName: "PREPARE_REPEATS:.*" {
        publishDir = [
            path: params.outdir,
            mode: 'copy',
            saveAs: { filename -> filename.equals('versions.yml') ? null : filename }
        ]
    }
}

// Dummy check_max function to make the above work
// DO NOT COPY. Your nf-core pipeline already has the correct implementation
def check_max(obj, type) {
    return obj
}
